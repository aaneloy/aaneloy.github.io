<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Asif Ahmed Neloy</title>

    <meta name="author" content="Asif Neloy">
    <meta name="google-site-verification" content="0CDfe8DbLbpfBmrg0qOUyJMpTXwBrAfd29-eOPkoGT4" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="icon" type="image/png" href="images/UofManitoba.png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">

    <!-- Structured Data: Person Schema -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Asif Ahmed Neloy",
      "url": "https://aaneloy.github.io/",
      "image": "https://aaneloy.github.io/images/asif.jpg",
      "sameAs": [
        "https://scholar.google.com/citations?user=WjL1EDcAAAAJ&hl=en",
        "https://github.com/aaneloy",
        "https://www.linkedin.com/in/aaneloy/"
      ],
      "jobTitle": "Teaching Professor",
      "worksFor": {
        "@type": "Organization",
        "name": "Douglas College"
      },
      "alumniOf": "University of Manitoba",
      "description": "Asif Ahmed Neloy is a Faculty Member at Douglas College, with research interests in Probabilistic and Bayesian Modeling, Anomaly Detection, and Machine Learning.",
      "email": "neloya@douglascollege.ca"
    }
    </script>
    <!-- End of Structured Data -->

  </head>

  <body>
    <table style="width:100%;max-width:900px;border:10px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color: #f4f4f4;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  <b>Asif Ahmed Neloy</b>

                  <p align="justify">
                    Asif Neloy is a <b>Faculty Member</b> at the <b>Department of Computing Studies and Information Systems (CSIS)</b> at <b><a href="https://www.douglascollege.ca/programs-courses/explore-programs-courses/faculties/commerce-and-business-administration/computing-studies-and-information-systems/faculty">Douglas College</a></b> in New Westminster, British Columbia. He also holds an adjunct <b>Faculty</b> position at the <b><a href="https://mfre.landfood.ubc.ca/faculty">University of British Columbia (UBC)</a></b>, Faculty of Land and Food Systems. Currently, he is teaching courses on Advanced Databases, System Analysis and Design, Data Analytics, and Fundamental Machine Learning. Aside from teaching, he is actively pursuing theoretical and applied research related to Probabilistic and Bayesian Modeling, Anomaly Detection, Dimension Reduction, and interdisciplinary applications of Auto-Encoders. Previously, he taught undergraduate and graduate courses at <b>British Columbia Institute of Technology (BCIT)</b>, <b>Vancouver Island University</b>, <b>University of Manitoba</b>, and <b>North South University</b>.</p>  

                  <p align="justify">
                  He obtained his MSc in <b>Computer Science</b> from <b>University of Manitoba</b>, supervised by <a href="https://www.maxturgeon.ca/">Dr. Maxime Turgeon</a> and <a href="https://cakcora.github.io/">Dr. Cüneyt Akçora</a>, focusing on <b>Dimension Reduction</b> and <b>Anomaly Detection</b> using Unsupervised Machine Learning. Along with Unsupervised settings, he has researched various Data Analytics methods, including Feature Extraction, Two-staged Modeling approaches, and Statistical Modeling under <a href="https://github.com/UMDimReduction">Dimension Reduction Lab</a> and NSERC CREATE fund on The Visual and Automated Disease Analytics <a href="https://vada.cs.umanitoba.ca/">(VADA)</a> Graduate Training program. Prior to that, he worked with <a href="http://ece.northsouth.edu/people/dr-shahnewaz-siddique/">Dr. Shahnewaz Siddique</a> on interdisciplinary research topics, including Robotics, Recommender Systems, Health Informatics, and Computer Vision.</p>
                <p style="text-align:center">
                  <a href="mailto:neloya@douglascollege.ca">Email</a> &nbsp;/&nbsp;
                  <a href="data/Asif_CV_2025.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/neloy_bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=WjL1EDcAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/aaneloy">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:20%">
                <a href="images/asif.jpg">
                  <img style="width:100%;max-width:100%;height:auto;object-fit: cover;" alt="profile photo" src="images/asif.jpg" class="hoverZoomLink">
                </a>
              </td>
              
              
            </tr>
          </tbody></table>

          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Recent News</h2>
                <ul>
                  <li> [November 2024] My paper titled "<b>Disentangled Conditional Variational Autoencoder for Unsupervised Anomaly Detection</b>" has been accepted at the IEEE Big Data Conference (IEEE BigData 2024) in Washington, D.C., taking place from December 15-18, 2024.</li>
                  <li> [July 2024] My paper titled "A Comprehensive Study of Auto-Encoders for Anomaly Detection: Efficiency and Trade-offs," published in the Machine Learning with Applications Journal, DOI: https://doi.org/10.1016/j.mlwa.2024.100572</li>
                  <li> [June 2024] Received Research Dissemination Present and Research Dissemination Publish Grant from Douglas College</li>
                  <li> [December 2023] Joined <b>Douglas College</b>, New Westminster Campus as a <b>Teaching Professor</b>.</li>
                  <li> [August 2023] Started my new journey as a <b>Faculty</b> Member, at the Vancouver Island University.</li>
                  <li> [May 2023] Promoted to Senior ML Engineer, Forum Inc</li>
                  <li> [February 2023] Lastest Published Conference Paper - <a href="https://doi.org/10.1109/ICDMW58026.2022.00064">Feature Extraction and Prediction of Combined Text and Survey Data using Two-Staged Modeling</a></li>
                  <li> [January 2023] My Msc dissertation, <a href="https://doi.org/10.1109/ICDMW58026.2022.00064">Dimension Reduction and Anomaly Detection using Unsupervised Machine</a> is now online</li>
                  <li> [November 2022] Guest Lecture, Introduction to Python and Numpy, STAT-447: Statistical Machine Learning for Data Science, Department of Mathematics and Statistics, University of Saskatchewan</li>
                  <li> [September 2022] Received Graduate Travel Award from University of Manitoba, NSERC CREATE VADA Program</li>
        
        </ul>
              </td>
            </tr>
          </tbody></table>

          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research</h2>
                  <p>
                    His research interests lie in the intersection of Supervised and Unsupervised Machine Learning, with a specific focus on Probabilistic and Bayesian Modeling, Anomaly Detection, and Dimension Reduction. Currently, he is exploring the intricacies of Auto-Encoders and their applications in Variational and Gaussian modeling. His work delves into the statistical interpretation and visualization of Unsupervised Machine Learning algorithms, emphasizing dimension reduction and anomaly detection. Additionally, he contributes to Data Engineering by developing interactive Python packages for tasks such as Data Cleaning, Visualization, Model Interpretation, Data Scaler Selection, and Statistical Analysis. Explore some of his Python packages on <a href="https://pypi.org/user/aaneloy/">PyPI.</a> Also, representative papers are <span class="highlight">highlighted</span>.
                  </p>
                </td>
              </tr>
            </tbody></table>

            <hr>
            <p style="text-align: center;">
              &nbsp;See my Google Scholar profile for the <a href="https://scholar.google.com/citations?user=WjL1EDcAAAAJ"> most recent publications</a>.
            </p>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <!-- New Paper -->
              <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" bgcolor="#ffffd0">
                <td width="25%">
                  <div class="one">
                    <div class="two" id='jump_image'><img src='images/dcvae.png' width="200"></div>
                    <img src='images/dcvae.png' width="200">
                  </div>
                  <script type="text/javascript">
                    function jump_start() {
                      document.getElementById('jump_image').style.opacity = "1";
                    }
                    function jump_stop() {
                      document.getElementById('jump_image').style.opacity = "0";
                    }
                    jump_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://github.com/UMDimReduction/Disentangled-Conditional-Variational-Autoencoder" target="_blank">
                    <span class="papertitle">Disentangled Conditional Variational Autoencoder for Unsupervised Anomaly Detection</span>
                  </a>
                  <br>
                  <a href="https://aaneloy.github.io/"><strong>Asif Ahmed Neloy</strong>*</a>, 
                  <a href="https://www.maxturgeon.ca/">Maxime Turgeon</a>,
                  <br>
                  <em>Accepted at the 2024 IEEE International Conference on Big Data (IEEE BigData 2024)</em>, 2024
                  <br>
                  <a href="https://github.com/UMDimReduction/Disentangled-Conditional-Variational-Autoencoder-dCVAE-">project page</a>
                  /
                  <a href="http://hdl.handle.net/1993/36999">UMSpace</a>
                  <p>
                    Generative models have recently become an effective approach for anomaly detection by leveraging auto-encoders to model high-dimensional data and identify anomalies based on reconstruction quality. However, a primary challenge in unsupervised anomaly detection (UAD) lies in learning meaningful, disentangled features without losing essential information. In this paper, we introduce a novel generative architecture that combines the frameworks of β-VAE, Conditional Variational Auto-encoder (CVAE), and the principle of total correlation (TC) to enhance feature disentanglement and retain critical information. Our approach improves the separation of latent features, optimizes TC loss more effectively, and enhances the detection of anomalies in complex, high-dimensional datasets such as image data. Through extensive qualitative and quantitative evaluations in benchmark datasets, we demonstrate that our method not only achieves strong performance in anomaly detection but also captures interpretable, disentangled representations, highlighting the importance of feature disentanglement in advancing UAD.</p>
                </td>
              </tr>
              <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" bgcolor="#ffffd0">
                <td width="25%">
                  <div class="one">
                    <div class="two" id='jump_image'><img src='images/mlwa.png' width="200"></div>
                    <img src='images/mlwa.png' width="200">
                  </div>
                  <script type="text/javascript">
                    function jump_start() {
                      document.getElementById('jump_image').style.opacity = "1";
                    }
                    function jump_stop() {
                      document.getElementById('jump_image').style.opacity = "0";
                    }
                    jump_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://doi.org/10.1016/j.mlwa.2024.100572" target="_blank">
                    <span class="papertitle">A comprehensive study of auto-encoders for anomaly detection: Efficiency and trade-offs</span>
                  </a>
                  <br>
                  <a href="https://aaneloy.github.io/"><strong>Asif Ahmed Neloy</strong>*</a>, 
                  <a href="https://www.maxturgeon.ca/">Maxime Turgeon</a>, 
                  <br>
                  <em>Machine Learning with Applications</em>, 2024
                  <br>
                  <a href="https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs">project page</a>
                  /
                  <a href="https://doi.org/10.1016/j.mlwa.2024.100572">DOI Link</a>
                  <p>
                    Unsupervised anomaly detection (UAD) is a diverse research area explored across various application domains. Over time, numerous anomaly detection techniques, including clustering, generative, and variational inference-based methods, are developed to address specific drawbacks and advance state-of-the-art techniques. Deep learning and generative models recently played a significant role in identifying unique challenges and devising advanced approaches. Auto-encoders (AEs) represent one such powerful technique that combines generative and probabilistic variational modeling with deep architecture. Auto-Encoder aims to learn the underlying data distribution to generate consequential sample data. This concept of data generation and the adoption of generative modeling have emerged in extensive research and variations in Auto-Encoder design, particularly in unsupervised representation learning. This study systematically reviews 11 Auto-Encoder architectures categorized into three groups, aiming to differentiate their reconstruction ability, sample generation, latent space visualization, and accuracy in classifying anomalous data using the Fashion-MNIST (FMNIST) and MNIST datasets. Additionally, we closely observed the reproducibility scope under different training parameters. We conducted reproducibility experiments utilizing similar model setups and hyperparameters and attempted to generate comparative results to address the scope of improvements for each Auto-Encoder. We conclude this study by analyzing the experimental results, which guide us in identifying the efficiency and trade-offs among auto-encoders, providing valuable insights into their performance and applicability in unsupervised anomaly detection techniques.</p>
                </td>
              </tr>
 
              <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" bgcolor="#ffffd0">
                <td width="25%">
                  <div class="one">
                    <div class="two" id='jump_image'><img src='images/icdm.png' width="200"></div>
                    <img src='images/icdm.png' width="200">
                  </div>
                  <script type="text/javascript">
                    function jump_start() {
                      document.getElementById('jump_image').style.opacity = "1";
                    }
                    function jump_stop() {
                      document.getElementById('jump_image').style.opacity = "0";
                    }
                    jump_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.computer.org/csdl/proceedings-article/icdmw/2022/460900a435/1KBqUqu7I7S" target="_blank">
                    <span class="papertitle">Feature Extraction and Prediction of Combined Text and Survey Data using Two-Staged Modeling</span>
                  </a>
                  <br>
                  <a href="https://aaneloy.github.io/"><strong>Asif Ahmed Neloy</strong>*</a>, 
                  <a href="https://www.maxturgeon.ca/">Maxime Turgeon</a>,
                  <br>
                  <em>ICDM</em>, 2022
                  <br>
                  <a href="https://github.com/aaneloy/ICDM2022">project page</a>
                  /
                  <a href="https://ieeexplore.ieee.org/abstract/document/10031068">IEEE</a>
                  <p>
                    Deep learning (DL) based natural language processing (NLP) has recently grown as one the fastest research domain and retained remarkable improvement in many applications. Due to the significant amount of data, the adaptation of feature learning and symmetric data efficiency is a critical underlying task in such applications. However, their ability to extract features is limited due to a lack of proper model formation. Moreover, the use of these methods on smaller datasets is unexplored and underdeveloped compared to more popular research areas. This work introduces a two-stage modeling approach to combine classical statistical analysis with NLP problems in a real-world dataset. We effectively layout a combination of the classical statistical model incorporating a stacked ensemble classifier and a DL framework of convolutional neural network (CNN) and Bidirectional Recurrent Neural Networks (Bi-RNN) to structure a more decomposed architecture with lower computational complexity. Additionally, the experimental results illustrating 96.69 % training and 70.56 % testing accuracy and hypothesis testing from our DL models followed by an ablation study empirically demonstrate the validation of our proposed combined modeling technique.</p>
                </td>
              </tr>
          
              <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" bgcolor="#ffffd0">
                <td width="25%">
                  <div class="one">
                    <div class="two" id='jump_image'><img src='images/icmlc.png' width="200"></div>
                    <img src='images/icmlc.png' width="200">
                  </div>
                  <script type="text/javascript">
                    function jump_start() {
                      document.getElementById('jump_image').style.opacity = "1";
                    }
                    function jump_stop() {
                      document.getElementById('jump_image').style.opacity = "0";
                    }
                    jump_stop()
                  </script>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://dl.acm.org/doi/abs/10.1145/3318299.3318377" target="_blank">
                    <span class="papertitle">Ensemble learning based rental apartment price prediction model by categorical features factoring</span>
                  </a>
                  <br>
                  <a href="https://aaneloy.github.io/"><strong>Asif Ahmed Neloy</strong>*</a>, 
                  <a href="">HM Sadman Haque</a>, 
                  <a href="">Md Mahmud Ul Islam</a>,
                  <br>
                  <em>ICMLC</em>, 2021
                  <br>
                  <a href="https://dl.acm.org/doi/abs/10.1145/3318299.3318377">ACM ICMLC</a>
                  <p>
                    Apartment rental prices are influenced by various factors. The aim of this study is to analyze the different features of an apartment and predict the rental price of it based on multiple factors. An ensemble learning based prediction model is created to reach the goal. We have used a dataset from bProperty.com which includes the rental price and different features of apartments in the city of Dhaka, Bangladesh. The results show the accuracy and prediction of the rent of an apartment, also indicates the different types of categorical values that affect the machine learning models. Another purpose of the study is to find out the factors that signify the apartment rental price in Dhaka. To help our prediction we take on the Advance Regression Techniques (ART) and compare to different features of an apartment for establishing an acceptable model. The following algorithms are selected as the base predictors -- Advance Linear Regression, Neural Network, Random Forest, Support Vector Machine (SVM) and Decision Tree Regressor. The Ensemble learning is stacked of following algorithms -- Ensemble AdaBoosting Regressor, Ensemble Gradient Boosting Regressor, Ensemble XGBoost. Also, Ridge Regression, Lasso Regression, and Elastic Net Regression has been used to combine the advance regression techniques. Tree-based algorithms generate a decision tree from categorical 'YES' and 'NO' values, Ensemble methods to boosting up the learning and prediction accuracy, Support Vector Machine to extend the model for both classification and regression approach and lastly advance linear regression to predict the house price with different features values.</p>
                </td>
              </tr>
            </tbody>
          </table>
          
                    

          <hr>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>
                <ul>
                  <li>
                    <b>Douglas College</b>
                    <br>
                    <ul>
                      <li>
                        <b>Summer 2024:</b>
                        <ul>
                          <li>CSIS 2300: Database I</li>
                          <li>CSIS 3300: Database II</li>
                          <li>CSIS 3360: Fundamentals of Data Analytics</li>
                          <!-- Add other courses under Winter 2024 as needed -->
                        </ul>
                      </li>
                      <li>
                        <b>Winter 2024:</b>
                        <ul>
                          <li>CSIS 2200: Systems Analysis & Design</li>
                          <li>CSIS 2300: Database I</li>
                          <li>CSIS 3290: <a href="https://github.com/aaneloy/CSIS-3290-Fundamentals-of-Machine-Learning-in-Data-Science">Fundamentals of Machine Learning in Data Science</a></li>
                          <!-- Add other courses under Summer 2024 as needed -->
                        </ul>
                      </li>
                      <!-- Add more entries for other semesters or colleges if necessary -->
                    </ul>
                  </li>
          
                  <!-- Add entries for Vancouver Island University -->
                  <li>
                    <b>Vancouver Island University</b>
                    <br>
                    <ul>
                      <li>
                        <b>Fall 2023:</b>
                        <ul>
                          <li>CSCI 159: Computer Science I</li>
                          <li>CSCI 112: Applications Programming</li>
                          <!-- Add other courses under Fall 2023 as needed -->
                        </ul>
                      </li>
                      <!-- Add more entries for other semesters if necessary -->
                    </ul>
                  </li>
          
                  <!-- Add entries for University of Manitoba -->
                  <li>
                    <b>University of Manitoba</b>
                    <br>
                    <ul>
                      <li>
                        <b>Winter 2023:</b>
                        <ul>
                          <li>DATA 2010: Tools and Techniques for Data Science</li>
                          <!-- Add other courses under Spring 2023 as needed -->
                        </ul>
                      </li>
                      <!-- Add more entries for other semesters if necessary -->
                    </ul>
                  </li>
          
                </ul>
              </td>
            </tr>
          </tbody></table>
          

        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Guest Lectures and Seminar Presentations</h2>
              <ul>
                <li>
                  <b>Invited Sessions:</b>
                  <ul>
                    <li>
                      <a href="https://icsa-canada-chapter.org/symposium2022/">ICSA-Canada Chapter 2022 Symposium</a>, Banff Center, Banff, Alberta, Canada.
                      <br>
                      <em>Topic:</em> Auto-encoders for Anomaly Detection: Efficiency and Trade-Offs.
                    </li>
                  </ul>
                </li>
        
                <li>
                  <b>Lectures:</b>
                  <ul>
                    <li>
                      <a href="https://github.com/aaneloy/Workshop-on-Machine-Learning-2018">Introduction to Machine Learning</a>, North South University, Dhaka, Bangladesh.
                    </li>
                    <li>
                      <b>Courses:</b> <a href="https://usask.instructure.com/courses/43914/assignments/syllabus">STAT 447: Statistical Machine Learning for Data Science</a>
                    </li>
                  </ul>
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        
        <hr>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>Python Packages</h2>
              <ul>
                <li>
                  <a href="https://pypi.org/project/DataScalerSelector/"><b>Data Scaler Selector</b></a>: Data Scaler is an open-source python library to select the appropriate data scaler for your Machine Learning model.
                </li>
                <li>
                  <a href="https://pypi.org/project/ImagetoSketch/"><b>Image to Sketch</b></a>: Python open-source library to convert color/ B&W image to pencil sketch.
                </li>
                <li>
                  <b>Data Preparer (On-Progress):</b> Data Preparer is an open-source Python package to Clean and Prepare your dataset before applying Machine Learning Model.
                </li>
              </ul>
            </td>
          </tr>
        </tbody></table>
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
          <tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Template credit-<a href="https://jonbarron.info/">Jon Barron</a>!<br>
                  Last updated: <span id="lastUpdated">September 04, 2024</span>.
                </p>
              </td>
            </tr>
          </tbody>
        </table>
        
        <p style="text-align: center; margin-top: 20px;">
          &copy; 2024 Asif. All rights reserved.
        </p>
        

  </body>
</html>
